{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53dee9c4-f1b5-403d-8ceb-1547b3ad5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "from sklearn.manifold import TSNE  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.datasets import fetch_openml  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Dense, Concatenate  \n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f5cdfe-e3b0-4506-aef4-2517729edf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集  \n",
    "mnist = fetch_openml('mnist_784', version=1)  \n",
    "X, y = mnist.data, mnist.target  \n",
    "X = X / 255.0  # 归一化数据  \n",
    "y = np.array([label for label in y])  \n",
    "y = to_categorical(y)  # 将标签转换为one-hot编码 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b01b49df-fab8-4ffe-a418-eaebaee2d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78e484a-b730-4ca5-8e08-bb5c7d569ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对原始数据进行标准化  \n",
    "scaler = StandardScaler()  \n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce06e537-9f07-40db-bafe-52b1b51d7822",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_scaled = np.vstack((X_train_scaled, X_test_scaled)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce487a9f-c98e-4724-bea4-fd2801692794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用t-SNE进行降维  \n",
    "tsne = TSNE(n_components=2, random_state=0)  \n",
    "# 对整个数据集进行降维  \n",
    "X_all_tsne = tsne.fit_transform(X_all_scaled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4084b1e9-fcd5-46be-bc0f-c2881aa9d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据原始数据的索引分割回训练集和测试集 \n",
    "n_train = X_train_scaled.shape[0]\n",
    "\n",
    "X_train_tsne = X_all_tsne[:n_train, :]  \n",
    "X_test_tsne = X_all_tsne[n_train:, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a4798c-1b17-47c4-8f3b-492e5f78a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将原始特征和降维后的特征堆叠起来  \n",
    "X_train_combined = np.concatenate((X_train_scaled, X_train_tsne), axis=1)  \n",
    "X_test_combined = np.concatenate((X_test_scaled, X_test_tsne), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9115dac8-97ca-48b8-9ac1-8474159e727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Concatenate  \n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0916864-41c4-4545-869d-e4531985726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义原始特征和t-SNE特征的输入层  \n",
    "input_original = Input(shape=(784,), name='original_input')\n",
    "input_tsne = Input(shape=(2,), name='tsne_input')\n",
    "  \n",
    "# 定义隐藏层，对每个输入进行处理  \n",
    "dense_original = Dense(64, activation='relu')(input_original)  \n",
    "dense_tsne = Dense(64, activation='relu')(input_tsne)  \n",
    "  \n",
    "# 连接两个隐藏层的输出  \n",
    "combined = Concatenate()([dense_original, dense_tsne])  \n",
    "  \n",
    "# 定义输出层  \n",
    "output = Dense(10)(combined)  \n",
    "  \n",
    "# 创建模型，输入是原始特征和t-SNE特征，输出是分类结果  \n",
    "model = Model(inputs=[input_original, input_tsne], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2783d258-084a-49d5-9bd8-f925313c295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译模型  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee65f88b-956f-4478-ba12-5fb04b56e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f60bc3e-69cd-4958-9dfc-89a3b4b39343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3122 - loss: 9.5691 - val_accuracy: 0.1951 - val_loss: 8.0644\n",
      "Epoch 2/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2440 - loss: 10.1877 - val_accuracy: 0.3491 - val_loss: 10.8616\n",
      "Epoch 3/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3049 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0965 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1007 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0981 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0996 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1008 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.1004 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m1750/1750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.0993 - loss: nan - val_accuracy: 0.0959 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2089f3c5b90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型  \n",
    "X_train_original = X_train_combined[:, :784]  \n",
    "X_train_tsne = X_train_combined[:, 784:]  \n",
    "X_test_original = X_test_combined[:, :784]  \n",
    "X_test_tsne = X_test_combined[:, 784:]  \n",
    "model.fit([X_train_original, X_train_tsne], y_train, epochs=10, batch_size=32,validation_data=([X_test_original,X_test_tsne], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4aca8f72-9622-45b4-9ae8-e51d6c555e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0980 - loss: nan\n",
      "Test accuracy: 0.09592857211828232\n"
     ]
    }
   ],
   "source": [
    "# 评估模型  \n",
    "_, accuracy = model.evaluate([X_test_original,X_test_tsne], y_test)  \n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
